{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3f19046-10a4-4dff-bb67-0f6faebb771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40597e0c-170b-4862-a51d-018f8685664f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df['IA_abs'] = np.abs(df['IA_50RT'])\n",
    "    df['pathNorm'] = df['pathlength'] / df['straightlength']\n",
    "    df['xTargetabs'] = np.abs(df['xTargetEnd'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95aa15b7-32ec-4171-b6d2-7130dc62098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to CSV with numeric column filtering and handling object columns\n",
    "def save_data_to_csv(df, results_dir, varlist):\n",
    "    # Filter out non-numeric columns to prevent mean aggregation errors\n",
    "    numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Group by specified columns and compute mean on numeric columns only\n",
    "    df_means = df.groupby(['group', \"visit\", 'studyid', 'subject', 'day', 'Condition', 'Affected'])[numeric_columns].mean().reset_index()\n",
    "    df_means.to_csv(os.path.join(results_dir, 'means_bysubject.csv'), index=False)\n",
    "\n",
    "    # Same logic for group by with 'Duration'\n",
    "    print(df.columns)\n",
    "    df_meansdur = df.groupby(['group', \"visit\", 'studyid', 'subject', 'day', 'Condition', 'Affected', 'Duration'])[numeric_columns].mean().reset_index()\n",
    "    df_meansdur.to_csv(os.path.join(results_dir, 'means_bysubjectandduration.csv'), index=False)\n",
    "\n",
    "    # Save Day 1 means\n",
    "    df1_means = df_means[df_means['day'] == 'Day1']\n",
    "    df1_means[['subject', 'group', 'day', 'Condition', 'Affected'] + varlist].to_csv('Day1_means_bysubject.csv', index=False)\n",
    "\n",
    "    # Save Day 2 means (if needed)\n",
    "    df2_means = df_means[df_means['day'] == 'Day2']\n",
    "    return df_means, df_meansdur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dce5eee-abe7-42d4-a5d3-ad49f79a233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def long_to_wide(df_means, varlist, results_dir):\n",
    "    df1_means = df_means[df_means['day'] == 'Day1']\n",
    "    df1_wide = df1_means[['subject', \"studyid\", 'group', 'day', 'Condition', 'Affected'] + varlist].pivot_table(\n",
    "        index=[\"subject\", \"studyid\", \"group\", \"day\"],\n",
    "        columns=['Condition', 'Affected'],\n",
    "        values=varlist)\n",
    "    df1_wide.sort_values(['group', 'subject'], ascending=True).to_csv(os.path.join(results_dir, 'Day1_means_bysubject_wide.csv'))\n",
    "    return df1_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd87d135-00ee-4bec-90e0-738d329eeb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_excel_sheets(df_means, df_meansdur, results_dir, varlist, total_ids=88, max_days=5):\n",
    "    all_ids = ['cpvib' + str(item).zfill(3) for item in range(1, total_ids + 1)]\n",
    "    exceltitle = os.path.join(results_dir, 'UL_KINARM_Mastersheet_Auto_Format.xlsx')\n",
    "    exceltitle2 = os.path.join(results_dir, 'UL_KINARM_Mastersheet_Long_Format.xlsx')\n",
    "    \n",
    "    for thisday in range(1, max_days + 1):\n",
    "        # Wide format per day\n",
    "        df1_means = df_means[df_means['day'] == 'Day' + str(thisday)]\n",
    "        df1_wide = df1_means[['subject', \"visit\", \"studyid\", 'group', 'day', 'Condition', 'Affected'] + varlist].pivot_table(\n",
    "            index=[\"subject\", \"visit\", \"studyid\", \"group\", \"day\"],\n",
    "            columns=['Condition', 'Affected'],\n",
    "            values=varlist)\n",
    "        df1_wide.columns = df1_wide.columns.to_flat_index()\n",
    "        df1_wide = df1_wide.reset_index(level=[\"subject\", \"visit\", \"group\", \"day\"])\n",
    "        missing = list(set(all_ids) - set(df1_wide.index.values))\n",
    "        df1_wide = df1_wide.reindex(df1_wide.index.union(missing))\n",
    "        df1_wide.index.name = 'NMSKL_ID'\n",
    "        df1_wide = df1_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'})\n",
    "        \n",
    "        # Wide format per day by duration\n",
    "        df1_meansdur = df_meansdur[df_meansdur['day'] == 'Day' + str(thisday)]\n",
    "        df1_widedur = df1_meansdur[['subject', \"visit\", \"studyid\", 'group', 'day', 'Condition', 'Affected', 'Duration'] + varlist].pivot_table(\n",
    "            index=[\"subject\", \"visit\", \"studyid\", \"group\", \"day\"],\n",
    "            columns=['Condition', 'Affected', 'Duration'],\n",
    "            values=varlist)\n",
    "        df1_widedur.columns = df1_widedur.columns.to_flat_index()\n",
    "        df1_widedur = df1_widedur.reset_index(level=[\"subject\", \"visit\", \"group\", \"day\"])\n",
    "        missing = list(set(all_ids) - set(df1_widedur.index.values))\n",
    "        df1_widedur = df1_widedur.reindex(df1_wide.index.union(missing))\n",
    "        df1_widedur.index.name = 'NMSKL_ID'\n",
    "        \n",
    "        # Combine and save to Excel\n",
    "        df_combo = pd.concat([df1_wide, df1_widedur], axis=1, join=\"inner\")\n",
    "        with pd.ExcelWriter(exceltitle, engine=\"openpyxl\", mode='a' if thisday > 1 else 'w') as writer: \n",
    "            df_combo.to_excel(writer, sheet_name=f'Day{thisday}_Master_Formatted')\n",
    "    \n",
    "    # Save all days' duration data\n",
    "    with pd.ExcelWriter(exceltitle2) as writer:\n",
    "        df_meansdur.to_excel(writer, sheet_name='AllDays_Master_Formatted')\n",
    "\n",
    "# Main execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8786f5bb-b5a1-45a7-af1f-e28666e1c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    all_df = pd.read_csv('all_processed_df.csv')\n",
    "    BASE_DIR = r'C:\\Users\\LibraryUser\\Downloads\\Fall2024/BrainAndAction\\CP\\CP'\n",
    "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "    RESULTS_DIR = os.path.join(BASE_DIR, 'resv2')\n",
    "    print(f\"Results Dir : {RESULTS_DIR}\")\n",
    "    results_dir = RESULTS_DIR\n",
    "\n",
    "    varlist = ['age', 'Accuracy', 'RT', 'MT', 'velPeak', 'pathlength', 'CT', 'xPosError', 'RTalt', 'IA_abs']\n",
    "    all_df = clean_data(all_df)\n",
    "    df_means, df_meansdur = save_data_to_csv(all_df, results_dir, varlist)\n",
    "\n",
    "    # Convert long to wide for Day 1\n",
    "    df1_wide = long_to_wide(df_means, varlist, results_dir)\n",
    "\n",
    "    # Create Owais-style Excel sheets\n",
    "    create_excel_sheets(df_means, df_meansdur, results_dir,varlist)\n",
    "    print(\"Success\")\n",
    "\n",
    "if __name__ == \"main\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "516f6d83-9c91-491f-8fc7-3e19266d8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab3db3d9-5411-46e4-b94e-cb7f4cb2549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('all_processed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c812d668-29a2-4c85-af94-643ccde4ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.columns\n",
    "all_df = clean_data(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab7e47b9-3cf6-4dd1-a661-5baeb4f09279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results Dir : C:\\Users\\LibraryUser\\Downloads\\Fall2024/BrainAndAction\\CP\\CP\\resv2\n"
     ]
    }
   ],
   "source": [
    "    all_df = pd.read_csv('all_processed_df.csv')\n",
    "    BASE_DIR = r'C:\\Users\\LibraryUser\\Downloads\\Fall2024/BrainAndAction\\CP\\CP'\n",
    "    DATA_DIR = os.path.join(BASE_DIR, 'data')\n",
    "    RESULTS_DIR = os.path.join(BASE_DIR, 'resv2')\n",
    "    print(f\"Results Dir : {RESULTS_DIR}\")\n",
    "    results_dir = RESULTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15a20fdf-c298-4a3f-80ee-7fd28b0caf91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "998400"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63a7679f-2993-4e4b-b80a-d7aa49d61102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Condition', 'Affected', 'TP', 'Duration', 'Accuracy', 'FeedbackTime',\n",
      "       'RT', 'CT', 'velPeak', 'xPosError', 'minDist', 'targetDist', 'handDist',\n",
      "       'straightlength', 'pathlength', 'targetlength', 'cursorX', 'cursorY',\n",
      "       'IA_RT', 'IA_50RT', 'RTalt', 'IA_RTalt', 'maxpathoffset',\n",
      "       'meanpathoffset', 'xTargetEnd', 'yTargetEnd', 'EndPointError', 'IDE',\n",
      "       'PLR', 'PLR_2', 'isCurveAround', 'MT', 'subject', 'age', 'visit', 'day',\n",
      "       'studyid', 'group', 'pathratio', 'IA_abs', 'pathNorm', 'xTargetabs'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert Duration, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11088\\1132504718.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvarlist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'age'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'velPeak'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pathlength'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'CT'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'xPosError'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RTalt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'IA_abs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mall_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_meansdur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msave_data_to_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11088\\1806205472.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df, results_dir, varlist)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdf_means\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'means_bysubject.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# Same logic for group by with 'Duration'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdf_meansdur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'group'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"visit\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'studyid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'subject'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'day'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Condition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Affected'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Duration'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumeric_columns\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mdf_meansdur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'means_bysubjectandduration.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;31m# Save Day 1 means\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[0;32m   6468\u001b[0m                     level_values = algorithms.take(\n\u001b[0;32m   6469\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6470\u001b[0m                     \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6472\u001b[1;33m                 new_obj.insert(\n\u001b[0m\u001b[0;32m   6473\u001b[0m                     \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6474\u001b[0m                     \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6475\u001b[0m                     \u001b[0mlevel_values\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   5154\u001b[0m                 \u001b[1;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5155\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5156\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5157\u001b[0m             \u001b[1;31m# Should this be a different kind of error??\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5158\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mcannot insert \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m, already exists\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5159\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5160\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loc must be int\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5161\u001b[0m         \u001b[1;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot insert Duration, already exists"
     ]
    }
   ],
   "source": [
    "varlist = ['age', 'Accuracy', 'RT', 'MT', 'velPeak', 'pathlength', 'CT', 'xPosError', 'RTalt', 'IA_abs']\n",
    "all_df = clean_data(all_df)\n",
    "df_means, df_meansdur = save_data_to_csv(all_df, results_dir, varlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2a19d9bd-71ec-4d91-9d04-ab2e3595e7c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "agg function failed [how->mean,dtype->object]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1942\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1941\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1942\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper\u001b[38;5;241m.\u001b[39magg_series(ser, alt, preserve_dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1943\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:864\u001b[0m, in \u001b[0;36mBaseGrouper.agg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    862\u001b[0m     preserve_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 864\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_series_pure_python(obj, func)\n\u001b[0;32m    866\u001b[0m npvalues \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mmaybe_convert_objects(result, try_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\groupby\\ops.py:885\u001b[0m, in \u001b[0;36mBaseGrouper._aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(splitter):\n\u001b[1;32m--> 885\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group)\n\u001b[0;32m    886\u001b[0m     res \u001b[38;5;241m=\u001b[39m extract_result(res)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2454\u001b[0m, in \u001b[0;36mGroupBy.mean.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   6548\u001b[0m ):\n\u001b[1;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[1;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[0;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_function(\n\u001b[0;32m  12421\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnanmean, axis, skipna, numeric_only, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m  12422\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[1;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[0;32m  12378\u001b[0m     func, name\u001b[38;5;241m=\u001b[39mname, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only\n\u001b[0;32m  12379\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   6456\u001b[0m     )\n\u001b[1;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(delegate, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[1;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m func(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, mask\u001b[38;5;241m=\u001b[39mmask, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\nanops.py:719\u001b[0m, in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m--> 719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m    720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m _ensure_numeric(the_sum)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\numpy\\_core\\_methods.py:53\u001b[0m, in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     52\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Save grouped data to CSV files\u001b[39;00m\n\u001b[0;32m     14\u001b[0m results_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresults_directory\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Ensure this directory is defined\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m df_means \u001b[38;5;241m=\u001b[39m all_df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudyid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCondition\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAffected\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m     17\u001b[0m df_means\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(results_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmeans_bysubject.csv\u001b[39m\u001b[38;5;124m'\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     19\u001b[0m df_meansdur \u001b[38;5;241m=\u001b[39m all_df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisit\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstudyid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCondition\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAffected\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuration\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mreset_index()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:2452\u001b[0m, in \u001b[0;36mGroupBy.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[0;32m   2446\u001b[0m         grouped_mean,\n\u001b[0;32m   2447\u001b[0m         executor\u001b[38;5;241m.\u001b[39mfloat_dtype_mapping,\n\u001b[0;32m   2448\u001b[0m         engine_kwargs,\n\u001b[0;32m   2449\u001b[0m         min_periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   2450\u001b[0m     )\n\u001b[0;32m   2451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2452\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[0;32m   2453\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2454\u001b[0m         alt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: Series(x, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only),\n\u001b[0;32m   2455\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[0;32m   2456\u001b[0m     )\n\u001b[0;32m   2457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[0;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[0;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1469\u001b[0m, in \u001b[0;36mBlockManager.grouped_reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1465\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_object:\n\u001b[0;32m   1466\u001b[0m     \u001b[38;5;66;03m# split on object-dtype blocks bc some columns may raise\u001b[39;00m\n\u001b[0;32m   1467\u001b[0m     \u001b[38;5;66;03m#  while others do not.\u001b[39;00m\n\u001b[0;32m   1468\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m sb \u001b[38;5;129;01min\u001b[39;00m blk\u001b[38;5;241m.\u001b[39m_split():\n\u001b[1;32m-> 1469\u001b[0m         applied \u001b[38;5;241m=\u001b[39m sb\u001b[38;5;241m.\u001b[39mapply(func)\n\u001b[0;32m   1470\u001b[0m         result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1995\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1992\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m   1994\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m alt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1995\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[0;32m   1996\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1946\u001b[0m, in \u001b[0;36mGroupBy._agg_py_fallback\u001b[1;34m(self, how, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1944\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg function failed [how->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhow\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,dtype->\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mser\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# preserve the kind of exception that raised\u001b[39;00m\n\u001b[1;32m-> 1946\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(err)(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ser\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m   1949\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m res_values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: agg function failed [how->mean,dtype->object]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate additional columns\n",
    "all_df['IA_abs'] = np.abs(all_df['IA_50RT'])\n",
    "all_df['pathNorm'] = all_df['pathlength'] / all_df['straightlength']\n",
    "all_df['xTargetabs'] = np.abs(all_df['xTargetEnd'])\n",
    "\n",
    "# Variables used for data extraction\n",
    "varlist = ['age', 'Accuracy', 'RT', 'MT', 'velPeak', 'pathlength', 'CT', 'xPosError', 'RTalt', 'IA_abs']\n",
    "\n",
    "# Save grouped data to CSV files\n",
    "results_dir = 'results_directory'  # Ensure this directory is defined\n",
    "\n",
    "df_means = all_df.groupby(['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected']).mean().reset_index()\n",
    "df_means.to_csv(os.path.join(results_dir, 'means_bysubject.csv'), index=False)\n",
    "\n",
    "df_meansdur = all_df.groupby(['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected', 'Duration']).mean().reset_index()\n",
    "df_meansdur.to_csv(os.path.join(results_dir, 'means_bysubjectandduration.csv'), index=False)\n",
    "\n",
    "# Filter and save Day 1 and Day 2 means\n",
    "hit_df = all_df[all_df['Accuracy'] == 1]\n",
    "\n",
    "df1_means = df_means[df_means['day'] == 'Day1']\n",
    "df1_means[['subject', 'group', 'day', 'Condition', 'Affected'] + varlist].to_csv('Day1_means_bysubject.csv', index=False)\n",
    "\n",
    "df2_means = df_means[df_means['day'] == 'Day2']\n",
    "\n",
    "# Convert long data to wide format for Day 1\n",
    "df1_wide = df1_means.pivot_table(\n",
    "    index=['subject', 'studyid', 'group', 'day'],\n",
    "    columns=['Condition', 'Affected'],\n",
    "    values=varlist\n",
    ").reset_index()\n",
    "\n",
    "df1_wide.sort_values(['group', 'subject'], ascending=True).to_csv(os.path.join(results_dir, 'Day1_means_bysubject_wide.csv'), index=False)\n",
    "\n",
    "# Excel Sheet Creation for Multiple Days\n",
    "total_ids = 88\n",
    "all_ids = ['cpvib' + str(item).zfill(3) for item in range(1, total_ids + 1)]\n",
    "\n",
    "exceltitle = os.path.join(results_dir, 'UL_KINARM_Mastersheet_Auto_Format.xlsx')\n",
    "exceltitle2 = os.path.join(results_dir, 'UL_KINARM_Mastersheet_Long_Format.xlsx')\n",
    "\n",
    "max_days = 5\n",
    "for day_num in range(1, max_days + 1):\n",
    "    current_day = f'Day{day_num}'\n",
    "    \n",
    "    # Process Day-Wise Wide Format Data\n",
    "    df_day_means = df_means[df_means['day'] == current_day]\n",
    "    df_day_wide = df_day_means.pivot_table(\n",
    "        index=['subject', 'visit', 'studyid', 'group', 'day'],\n",
    "        columns=['Condition', 'Affected'],\n",
    "        values=varlist\n",
    "    ).reset_index()\n",
    "    df_day_wide.columns = df_day_wide.columns.to_flat_index()\n",
    "    df_day_wide = df_day_wide.set_index('subject').reindex(all_ids).reset_index()\n",
    "    \n",
    "    df_day_wide.index.name = 'NMSKL_ID'\n",
    "    df_day_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "\n",
    "    # Process Day-Wise Data by Duration\n",
    "    df_day_meansdur = df_meansdur[df_meansdur['day'] == current_day]\n",
    "    df_day_widedur = df_day_meansdur.pivot_table(\n",
    "        index=['subject', 'visit', 'studyid', 'group', 'day'],\n",
    "        columns=['Condition', 'Affected', 'Duration'],\n",
    "        values=varlist\n",
    "    ).reset_index()\n",
    "    df_day_widedur.columns = df_day_widedur.columns.to_flat_index()\n",
    "    df_day_widedur = df_day_widedur.set_index('subject').reindex(all_ids).reset_index()\n",
    "    \n",
    "    df_day_widedur.index.name = 'NMSKL_ID'\n",
    "    df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
    "\n",
    "    # Combine the data and write to Excel\n",
    "    df_combo = pd.concat([df_day_wide, df_day_widedur], axis=1, join=\"inner\")\n",
    "\n",
    "    if day_num == 1:\n",
    "        with pd.ExcelWriter(exceltitle) as writer:\n",
    "            df_combo.to_excel(writer, sheet_name=f'{current_day}_Master_Formatted', index=False)\n",
    "    else:\n",
    "        with pd.ExcelWriter(exceltitle, engine=\"openpyxl\", mode='a') as writer:\n",
    "            df_combo.to_excel(writer, sheet_name=f'{current_day}_Master_Formatted', index=False)\n",
    "\n",
    "# Save long format Excel file for all days\n",
    "df_meansdur.to_excel(exceltitle2, sheet_name='AllDays_Master_Formatted', index=False)\n",
    "\n",
    "# Potential Fixes and Improvements:\n",
    "# - Defined a results directory for output files to avoid errors.\n",
    "# - Added explicit reset_index() calls to ensure proper reshaping.\n",
    "# - Replaced ambiguous .loc[] indexing with more readable conditional indexing.\n",
    "# - Improved file naming for consistency and removed unnecessary comments.\n",
    "# - Ensured to specify index=False to avoid writing index columns to CSV/Excel.\n",
    "# - Added handling for missing IDs in wide dataframes to ensure consistent shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "907ea008-1d4e-4e46-931d-57a929def375",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['subject'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11088\\2630831554.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;31m# Save long format Excel file for all days\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0msave_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_meansdur\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexceltitle2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'AllDays_Master_Formatted'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11088\\2630831554.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mdf1_means\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'subject'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'group'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'day'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Condition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Affected'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mVARLIST\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Day1_means_bysubject.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m# Convert long data to wide format for Day 1 and save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mdf1_wide\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpivot_data_to_wide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1_means\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'subject'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'studyid'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'group'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'day'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Condition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Affected'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVARLIST\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0mdf1_wide\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreindex_with_missing_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1_wide\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mALL_IDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mdf1_wide\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'subject'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'KINARM_ID'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'day'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'Visit_day'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mdf1_wide\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'group'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'KINARM_ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRESULTS_DIR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Day1_means_bysubject_wide.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11088\\2630831554.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(df, all_ids)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreindex_with_missing_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'subject'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'NMSKL_ID'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   6118\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6119\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6122\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33mf\"\u001b[0m\u001b[1;33mNone of \u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmissing\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m are in the columns\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6125\u001b[0m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['subject'] are in the columns\""
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define constants\n",
    "RESULTS_DIR = r'C:\\Users\\LibraryUser\\Downloads\\Fall2024/BrainAndAction\\CP\\CP\\resv2'  # Ensure this directory is defined\n",
    "TOTAL_IDS = 88\n",
    "ALL_IDS = ['cpvib' + str(item).zfill(3) for item in range(1, TOTAL_IDS + 1)]\n",
    "MAX_DAYS = 5\n",
    "VARLIST = ['age', 'Accuracy', 'RT', 'MT', 'velPeak', 'pathlength', 'CT', 'xPosError', 'RTalt', 'IA_abs']\n",
    "\n",
    "# Helper functions\n",
    "def calculate_additional_columns(df):\n",
    "    df['IA_abs'] = np.abs(df['IA_50RT'])\n",
    "    df['pathNorm'] = df['pathlength'] / df['straightlength']\n",
    "    df['xTargetabs'] = np.abs(df['xTargetEnd'])\n",
    "    return df\n",
    "\n",
    "def save_grouped_data(df, group_cols, filename):\n",
    "    grouped_df = df.groupby(group_cols).mean(numeric_only=True).reset_index()\n",
    "    grouped_df.to_csv(os.path.join(RESULTS_DIR, filename), index=False)\n",
    "    return grouped_df\n",
    "\n",
    "def pivot_data_to_wide(df, index_cols, pivot_cols, values_cols):\n",
    "    wide_df = df.pivot_table(index=index_cols, columns=pivot_cols, values=values_cols).reset_index()\n",
    "    wide_df.columns = wide_df.columns.to_flat_index()\n",
    "    return wide_df\n",
    "\n",
    "def reindex_with_missing_ids(df, all_ids):\n",
    "    df = df.set_index('subject').reindex(all_ids).reset_index()\n",
    "    df.index.name = 'NMSKL_ID'\n",
    "    return df\n",
    "\n",
    "def save_excel(df, filepath, sheet_name, mode='w'):\n",
    "    with pd.ExcelWriter(filepath, engine='openpyxl', mode=mode) as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# Main processing\n",
    "def main():\n",
    "    # Load and calculate additional columns\n",
    "    all_df = pd.read_csv('all_processed_df.csv')  # Assuming input data is loaded from a CSV\n",
    "    all_df = calculate_additional_columns(all_df)\n",
    "\n",
    "    # Save grouped data to CSV files\n",
    "    df_means = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected'], 'means_bysubject.csv')\n",
    "    df_meansdur = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected', 'Duration'], 'means_bysubjectandduration.csv')\n",
    "\n",
    "    # Filter and save Day 1 means\n",
    "    df1_means = df_means[df_means['day'] == 'Day1']\n",
    "    df1_means[['subject', 'group', 'day', 'Condition', 'Affected'] + VARLIST].to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject.csv'), index=False)\n",
    "\n",
    "    # Convert long data to wide format for Day 1 and save\n",
    "    df1_wide = pivot_data_to_wide(df1_means, ['subject', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "    df1_wide = reindex_with_missing_ids(df1_wide, ALL_IDS)\n",
    "    df1_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "    df1_wide.sort_values(['group', 'KINARM_ID'], ascending=True).to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject_wide.csv'), index=False)\n",
    "\n",
    "    # Excel Sheet Creation for Multiple Days\n",
    "    exceltitle = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Auto_Format.xlsx')\n",
    "    exceltitle2 = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Long_Format.xlsx')\n",
    "\n",
    "    for day_num in range(1, MAX_DAYS + 1):\n",
    "        current_day = f'Day{day_num}'\n",
    "\n",
    "        # Process Day-Wise Wide Format Data\n",
    "        df_day_means = df_means[df_means['day'] == current_day]\n",
    "        df_day_wide = pivot_data_to_wide(df_day_means, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "        df_day_wide = reindex_with_missing_ids(df_day_wide, ALL_IDS)\n",
    "        df_day_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "\n",
    "        # Process Day-Wise Data by Duration\n",
    "        df_day_meansdur = df_meansdur[df_meansdur['day'] == current_day]\n",
    "        df_day_widedur = pivot_data_to_wide(df_day_meansdur, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected', 'Duration'], VARLIST)\n",
    "        df_day_widedur = reindex_with_missing_ids(df_day_widedur, ALL_IDS)\n",
    "        df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
    "\n",
    "        # Combine the data and write to Excel\n",
    "        df_combo = pd.concat([df_day_wide, df_day_widedur], axis=1, join=\"inner\")\n",
    "\n",
    "        if day_num == 1:\n",
    "            save_excel(df_combo, exceltitle, f'{current_day}_Master_Formatted', mode='w')\n",
    "        else:\n",
    "            save_excel(df_combo, exceltitle, f'{current_day}_Master_Formatted', mode='a')\n",
    "\n",
    "    # Save long format Excel file for all days\n",
    "    save_excel(df_meansdur, exceltitle2, 'AllDays_Master_Formatted', mode='w')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5fde68f-5951-4940-9674-5646b8b3eb36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\LibraryUser\\\\Downloads\\\\Fall2024/BrainAndAction\\\\CP\\\\CP\\\\resv2'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74f7a59b-1876-4bd2-90fd-aeb33e85657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define constants\n",
    "# RESULTS_DIR = 'results_directory'  # Ensure this directory is defined\n",
    "TOTAL_IDS = 88\n",
    "ALL_IDS = ['cpvib' + str(item).zfill(3) for item in range(1, TOTAL_IDS + 1)]\n",
    "MAX_DAYS = 5\n",
    "VARLIST = ['age', 'Accuracy', 'RT', 'MT', 'velPeak', 'pathlength', 'CT', 'xPosError', 'RTalt', 'IA_abs']\n",
    "\n",
    "# Helper functions\n",
    "def calculate_additional_columns(df):\n",
    "    df['IA_abs'] = np.abs(df['IA_50RT'])\n",
    "    df['pathNorm'] = df['pathlength'] / df['straightlength']\n",
    "    df['xTargetabs'] = np.abs(df['xTargetEnd'])\n",
    "    return df\n",
    "\n",
    "def save_grouped_data(df, group_cols, filename):\n",
    "    grouped_df = df.groupby(group_cols).mean(numeric_only=True).reset_index()\n",
    "    grouped_df.to_csv(os.path.join(RESULTS_DIR, filename), index=False)\n",
    "    return grouped_df\n",
    "\n",
    "def pivot_data_to_wide(df, index_cols, pivot_cols, values_cols):\n",
    "    wide_df = df.pivot_table(index=index_cols, columns=pivot_cols, values=values_cols).reset_index()\n",
    "    wide_df.columns = ['_'.join(filter(None, map(str, col))).strip() for col in wide_df.columns.values]\n",
    "    return wide_df\n",
    "\n",
    "def reindex_with_missing_ids(df, all_ids):\n",
    "    df['subject'] = df['subject'].astype(str)\n",
    "    df = df.set_index('subject').reindex(all_ids).reset_index()\n",
    "    df.index.name = 'NMSKL_ID'\n",
    "    return df\n",
    "\n",
    "def save_excel(df, filepath, sheet_name, mode='w'):\n",
    "    with pd.ExcelWriter(filepath, engine='openpyxl', mode=mode) as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# Main processing\n",
    "def main():\n",
    "    # Load and calculate additional columns\n",
    "    all_df = pd.read_csv('all_processed_df.csv')  # Assuming input data is loaded from a CSV\n",
    "    all_df = calculate_additional_columns(all_df)\n",
    "\n",
    "    # Save grouped data to CSV files\n",
    "    df_means = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected'], 'means_bysubject.csv')\n",
    "    df_meansdur = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected', 'Duration'], 'means_bysubjectandduration.csv')\n",
    "\n",
    "    # Filter and save Day 1 means\n",
    "    df1_means = df_means[df_means['day'] == 'Day1']\n",
    "    df1_means[['subject', 'group', 'day', 'Condition', 'Affected'] + VARLIST].to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject.csv'), index=False)\n",
    "\n",
    "    # Convert long data to wide format for Day 1 and save\n",
    "    df1_wide = pivot_data_to_wide(df1_means, ['subject', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "    df1_wide = reindex_with_missing_ids(df1_wide, ALL_IDS)\n",
    "    df1_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "    df1_wide.sort_values(['group', 'KINARM_ID'], ascending=True).to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject_wide.csv'), index=False)\n",
    "\n",
    "    # Excel Sheet Creation for Multiple Days\n",
    "    exceltitle = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Auto_Format.xlsx')\n",
    "    exceltitle2 = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Long_Format.xlsx')\n",
    "\n",
    "    for day_num in range(1, MAX_DAYS + 1):\n",
    "        current_day = f'Day{day_num}'\n",
    "\n",
    "        # Process Day-Wise Wide Format Data\n",
    "        df_day_means = df_means[df_means['day'] == current_day]\n",
    "        df_day_wide = pivot_data_to_wide(df_day_means, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "        df_day_wide = reindex_with_missing_ids(df_day_wide, ALL_IDS)\n",
    "        df_day_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "\n",
    "        # Process Day-Wise Data by Duration\n",
    "        df_day_meansdur = df_meansdur[df_meansdur['day'] == current_day]\n",
    "        df_day_widedur = pivot_data_to_wide(df_day_meansdur, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected', 'Duration'], VARLIST)\n",
    "        df_day_widedur = reindex_with_missing_ids(df_day_widedur, ALL_IDS)\n",
    "        df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
    "\n",
    "        # Combine the data and write to Excel\n",
    "        df_combo = pd.concat([df_day_wide, df_day_widedur], axis=1, join=\"outer\")\n",
    "\n",
    "        if day_num == 1:\n",
    "            save_excel(df_combo, exceltitle, f'{current_day}_Master_Formatted', mode='w')\n",
    "        else:\n",
    "            save_excel(df_combo, exceltitle, f'{current_day}_Master_Formatted', mode='a')\n",
    "\n",
    "    # Save long format Excel file for all days\n",
    "    save_excel(df_meansdur, exceltitle2, 'AllDays_Master_Formatted', mode='w')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4bf06375-bc11-434d-a9ca-fc7a4ad7aad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LibraryUser\\AppData\\Local\\Temp\\ipykernel_11088\\2852807684.py:77: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
      "C:\\Users\\LibraryUser\\AppData\\Local\\Temp\\ipykernel_11088\\2852807684.py:77: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
      "C:\\Users\\LibraryUser\\AppData\\Local\\Temp\\ipykernel_11088\\2852807684.py:77: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
      "C:\\Users\\LibraryUser\\AppData\\Local\\Temp\\ipykernel_11088\\2852807684.py:77: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
      "C:\\Users\\LibraryUser\\AppData\\Local\\Temp\\ipykernel_11088\\2852807684.py:77: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define constant\n",
    "RESULTS_DIR = r'C:\\\\Users\\\\LibraryUser\\\\Downloads\\\\Fall2024/BrainAndAction\\\\CP\\\\CP\\\\resv2'\n",
    "\n",
    "TOTAL_IDS = 88\n",
    "ALL_IDS = ['cpvib' + str(item).zfill(3) for item in range(1, TOTAL_IDS + 1)]\n",
    "MAX_DAYS = 5\n",
    "VARLIST = ['age', 'Accuracy', 'RT', 'MT', 'velPeak', 'pathlength', 'CT', 'xPosError', 'RTalt', 'IA_abs']\n",
    "\n",
    "# Helper functions\n",
    "def calculate_additional_columns(df):\n",
    "    df['IA_abs'] = np.abs(df['IA_50RT'])\n",
    "    df['pathNorm'] = df['pathlength'] / df['straightlength']\n",
    "    df['xTargetabs'] = np.abs(df['xTargetEnd'])\n",
    "    return df\n",
    "\n",
    "def save_grouped_data(df, group_cols, filename):\n",
    "    grouped_df = df.groupby(group_cols).mean(numeric_only=True).reset_index()\n",
    "    grouped_df.to_csv(os.path.join(RESULTS_DIR, filename), index=False)\n",
    "    return grouped_df\n",
    "\n",
    "def pivot_data_to_wide(df, index_cols, pivot_cols, values_cols):\n",
    "    wide_df = df.pivot_table(index=index_cols, columns=pivot_cols, values=values_cols)\n",
    "    wide_df.columns = pd.MultiIndex.from_tuples(wide_df.columns)\n",
    "    wide_df = wide_df.reset_index()\n",
    "    return wide_df\n",
    "\n",
    "def reindex_with_missing_ids(df, all_ids, index_name='NMSKL_ID'):\n",
    "    df = df.set_index('subject').reindex(all_ids).reset_index()\n",
    "    df.index.name = index_name\n",
    "    return df\n",
    "\n",
    "def save_excel(df, filepath, sheet_name, mode='w'):\n",
    "    with pd.ExcelWriter(filepath, engine='openpyxl', mode=mode) as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "# Main processing\n",
    "def main():\n",
    "    # Load and calculate additional columns\n",
    "    all_df = pd.read_csv('all_processed_df.csv')  # Assuming input data is loaded from a CSV\n",
    "    all_df = calculate_additional_columns(all_df)\n",
    "\n",
    "    # Save grouped data to CSV files\n",
    "    df_means = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected'], 'means_bysubject.csv')\n",
    "    df_meansdur = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected', 'Duration'], 'means_bysubjectandduration.csv')\n",
    "\n",
    "    # Filter and save Day 1 means\n",
    "    df1_means = df_means[df_means['day'] == 'Day1']\n",
    "    df1_means[['subject', 'group', 'day', 'Condition', 'Affected'] + VARLIST].to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject.csv'), index=False)\n",
    "\n",
    "    # Convert long data to wide format for Day 1 and save\n",
    "    df1_wide = pivot_data_to_wide(df1_means, ['subject', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "    df1_wide = reindex_with_missing_ids(df1_wide, ALL_IDS)\n",
    "    df1_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "    df1_wide.sort_values(['group', 'KINARM_ID'], ascending=True).to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject_wide.csv'), index=False)\n",
    "\n",
    "    # Excel Sheet Creation for Multiple Days\n",
    "    exceltitle = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Auto_Format.xlsx')\n",
    "    exceltitle2 = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Long_Format.xlsx')\n",
    "\n",
    "    for day_num in range(1, MAX_DAYS + 1):\n",
    "        current_day = f'Day{day_num}'\n",
    "\n",
    "        # Process Day-Wise Wide Format Data\n",
    "        df_day_means = df_means[df_means['day'] == current_day]\n",
    "        df_day_wide = pivot_data_to_wide(df_day_means, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "        df_day_wide = reindex_with_missing_ids(df_day_wide, ALL_IDS)\n",
    "        df_day_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "\n",
    "        # Process Day-Wise Data by Duration\n",
    "        df_day_meansdur = df_meansdur[df_meansdur['day'] == current_day]\n",
    "        df_day_widedur = pivot_data_to_wide(df_day_meansdur, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected', 'Duration'], VARLIST)\n",
    "        df_day_widedur = reindex_with_missing_ids(df_day_widedur, ALL_IDS)\n",
    "        df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
    "\n",
    "        # Combine the data and write to Excel\n",
    "        df_combo = pd.concat([df_day_wide, df_day_widedur], axis=1, join=\"outer\")\n",
    "\n",
    "        if day_num == 1:\n",
    "            save_excel(df_combo, exceltitle, f'{current_day}_Master_Formatted', mode='w')\n",
    "        else:\n",
    "            save_excel(df_combo, exceltitle, f'{current_day}_Master_Formatted', mode='a')\n",
    "\n",
    "    # Save long format Excel file for all days\n",
    "    save_excel(df_meansdur, exceltitle2, 'AllDays_Master_Formatted', mode='w')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cf1ef59a-56e0-445d-b3d6-9ee65309d263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LibraryUser\\AppData\\Local\\Temp\\ipykernel_11088\\1653975767.py:77: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot handle a non-unique multi-index!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 98\u001b[0m\n\u001b[0;32m     95\u001b[0m     save_excel(df_meansdur, exceltitle2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAllDays_Master_Formatted\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 98\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[55], line 87\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m ordered_columns \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_product([\n\u001b[0;32m     81\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRT\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpathlength\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvelPeak\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     82\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInterception\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReaching\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     83\u001b[0m     [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLess Affected\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMore Affected\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     84\u001b[0m     DURATION_VALUES \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m     85\u001b[0m ])\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     86\u001b[0m df_day_combo \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df_day_wide, df_day_widedur], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, join\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 87\u001b[0m df_day_combo \u001b[38;5;241m=\u001b[39m df_day_combo\u001b[38;5;241m.\u001b[39mreindex(columns\u001b[38;5;241m=\u001b[39mordered_columns, fill_value\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m day_num \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     90\u001b[0m     save_excel(df_day_combo, exceltitle, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_day\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_Master_Formatted\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\frame.py:5378\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5359\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   5360\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,\n\u001b[0;32m   5361\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5376\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5377\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 5378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[0;32m   5379\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[0;32m   5380\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   5381\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   5382\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   5383\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m   5384\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5385\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   5386\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5387\u001b[0m         limit\u001b[38;5;241m=\u001b[39mlimit,\n\u001b[0;32m   5388\u001b[0m         tolerance\u001b[38;5;241m=\u001b[39mtolerance,\n\u001b[0;32m   5389\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\generic.py:5610\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5609\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_axes(\n\u001b[0;32m   5611\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[0;32m   5612\u001b[0m )\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\generic.py:5633\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5630\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   5632\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5633\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mreindex(\n\u001b[0;32m   5634\u001b[0m     labels, level\u001b[38;5;241m=\u001b[39mlevel, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance, method\u001b[38;5;241m=\u001b[39mmethod\n\u001b[0;32m   5635\u001b[0m )\n\u001b[0;32m   5637\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m   5638\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5639\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   5640\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5641\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5642\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5643\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\cp\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4426\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4422\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer(\n\u001b[0;32m   4423\u001b[0m         target, method\u001b[38;5;241m=\u001b[39mmethod, limit\u001b[38;5;241m=\u001b[39mlimit, tolerance\u001b[38;5;241m=\u001b[39mtolerance\n\u001b[0;32m   4424\u001b[0m     )\n\u001b[0;32m   4425\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_multi:\n\u001b[1;32m-> 4426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   4428\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[0;32m   4429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot handle a non-unique multi-index!"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define constants\n",
    "RESULTS_DIR = r'C:\\\\Users\\\\LibraryUser\\\\Downloads\\\\Fall2024/BrainAndAction\\\\CP\\\\CP\\\\resv2'\n",
    "TOTAL_IDS = 88\n",
    "ALL_IDS = ['cpvib' + str(item).zfill(3) for item in range(1, TOTAL_IDS + 1)]\n",
    "MAX_DAYS = 5\n",
    "VARLIST = ['age', 'Accuracy', 'RT', 'MT', 'velPeak', 'pathlength', 'CT', 'xPosError', 'RTalt', 'IA_abs']\n",
    "DURATION_VALUES = [500, 625, 750, 900]\n",
    "\n",
    "# Helper functions\n",
    "def calculate_additional_columns(df):\n",
    "    df['IA_abs'] = np.abs(df['IA_50RT'])\n",
    "    df['pathNorm'] = df['pathlength'] / df['straightlength']\n",
    "    df['xTargetabs'] = np.abs(df['xTargetEnd'])\n",
    "    return df\n",
    "\n",
    "def save_grouped_data(df, group_cols, filename):\n",
    "    grouped_df = df.groupby(group_cols).mean(numeric_only=True).reset_index()\n",
    "    grouped_df.to_csv(os.path.join(RESULTS_DIR, filename), index=False)\n",
    "    return grouped_df\n",
    "\n",
    "def pivot_data_to_wide(df, index_cols, pivot_cols, values_cols):\n",
    "    wide_df = df.pivot_table(index=index_cols, columns=pivot_cols, values=values_cols)\n",
    "    wide_df.columns = pd.MultiIndex.from_tuples(wide_df.columns)\n",
    "    wide_df = wide_df.reset_index()\n",
    "    return wide_df\n",
    "\n",
    "def reindex_with_missing_ids(df, all_ids, index_name='NMSKL_ID'):\n",
    "    df = df.set_index('subject').reindex(all_ids).reset_index()\n",
    "    df.index.name = index_name\n",
    "    return df\n",
    "\n",
    "def save_excel(df, filepath, sheet_name, mode='w'):\n",
    "    with pd.ExcelWriter(filepath, engine='openpyxl', mode=mode) as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# Main processing\n",
    "def main():\n",
    "    # Load and calculate additional columns\n",
    "    all_df = pd.read_csv('all_processed_df.csv')  # Assuming input data is loaded from a CSV\n",
    "    all_df = calculate_additional_columns(all_df)\n",
    "\n",
    "    # Save grouped data to CSV files\n",
    "    df_means = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected'], 'means_bysubject.csv')\n",
    "    df_meansdur = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected', 'Duration'], 'means_bysubjectandduration.csv')\n",
    "\n",
    "    # Filter and save Day 1 means\n",
    "    df1_means = df_means[df_means['day'] == 'Day1']\n",
    "    df1_means[['subject', 'group', 'day', 'Condition', 'Affected'] + VARLIST].to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject.csv'), index=False)\n",
    "\n",
    "    # Convert long data to wide format for Day 1 and save\n",
    "    df1_wide = pivot_data_to_wide(df1_means, ['subject', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "    df1_wide = reindex_with_missing_ids(df1_wide, ALL_IDS)\n",
    "    df1_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "    df1_wide.sort_values(['group', 'KINARM_ID'], ascending=True).to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject_wide.csv'), index=False)\n",
    "\n",
    "    # Excel Sheet Creation for Multiple Days\n",
    "    exceltitle = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Auto_Format.xlsx')\n",
    "    exceltitle2 = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Long_Format.xlsx')\n",
    "\n",
    "    for day_num in range(1, MAX_DAYS + 1):\n",
    "        current_day = f'Day{day_num}'\n",
    "\n",
    "        # Process Day-Wise Wide Format Data\n",
    "        df_day_means = df_means[df_means['day'] == current_day]\n",
    "        df_day_wide = pivot_data_to_wide(df_day_means, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "        df_day_wide = reindex_with_missing_ids(df_day_wide, ALL_IDS)\n",
    "        df_day_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "\n",
    "        # Process Day-Wise Data by Duration\n",
    "        df_day_meansdur = df_meansdur[df_meansdur['day'] == current_day]\n",
    "        df_day_widedur = pivot_data_to_wide(df_day_meansdur, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected', 'Duration'], VARLIST)\n",
    "        df_day_widedur = reindex_with_missing_ids(df_day_widedur, ALL_IDS)\n",
    "        df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
    "\n",
    "        # Ensure the correct ordering of columns to match the expected output\n",
    "        ordered_columns = pd.MultiIndex.from_product([\n",
    "            ['Accuracy', 'MT', 'RT', 'pathlength', 'velPeak'],\n",
    "            ['Interception', 'Reaching'],\n",
    "            ['Less Affected', 'More Affected'],\n",
    "            DURATION_VALUES + [None]\n",
    "        ]).dropna().tolist()\n",
    "        df_day_combo = pd.concat([df_day_wide, df_day_widedur], axis=1, join=\"outer\")\n",
    "        df_day_combo = df_day_combo.reindex(columns=ordered_columns, fill_value=np.nan)\n",
    "\n",
    "        if day_num == 1:\n",
    "            save_excel(df_day_combo, exceltitle, f'{current_day}_Master_Formatted', mode='w')\n",
    "        else:\n",
    "            save_excel(df_day_combo, exceltitle, f'{current_day}_Master_Formatted', mode='a')\n",
    "\n",
    "    # Save long format Excel file for all days\n",
    "    save_excel(df_meansdur, exceltitle2, 'AllDays_Master_Formatted', mode='w')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2de2ed6e-6ad8-4d63-8fe5-7750f4aa3b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LibraryUser\\AppData\\Local\\Temp\\ipykernel_11088\\3652772879.py:81: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
      "C:\\Users\\LibraryUser\\AppData\\Local\\Temp\\ipykernel_11088\\3652772879.py:81: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
      "C:\\Users\\LibraryUser\\AppData\\Local\\Temp\\ipykernel_11088\\3652772879.py:81: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
      "C:\\Users\\LibraryUser\\AppData\\Local\\Temp\\ipykernel_11088\\3652772879.py:81: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
      "C:\\Users\\LibraryUser\\AppData\\Local\\Temp\\ipykernel_11088\\3652772879.py:81: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define constants\n",
    "RESULTS_DIR = r'C:\\\\Users\\\\LibraryUser\\\\Downloads\\\\Fall2024/BrainAndAction\\\\CP\\\\CP\\\\resv2'\n",
    "TOTAL_IDS = 88\n",
    "ALL_IDS = ['cpvib' + str(item).zfill(3) for item in range(1, TOTAL_IDS + 1)]\n",
    "MAX_DAYS = 5\n",
    "VARLIST = ['age', 'Accuracy', 'RT', 'MT', 'velPeak', 'pathlength', 'CT', 'xPosError', 'RTalt', 'IA_abs']\n",
    "DURATION_VALUES = [500, 625, 750, 900]\n",
    "\n",
    "# Helper functions\n",
    "def calculate_additional_columns(df):\n",
    "    df['IA_abs'] = np.abs(df['IA_50RT'])\n",
    "    df['pathNorm'] = df['pathlength'] / df['straightlength']\n",
    "    df['xTargetabs'] = np.abs(df['xTargetEnd'])\n",
    "    return df\n",
    "\n",
    "def save_grouped_data(df, group_cols, filename):\n",
    "    grouped_df = df.groupby(group_cols).mean(numeric_only=True).reset_index()\n",
    "    grouped_df.to_csv(os.path.join(RESULTS_DIR, filename), index=False)\n",
    "    return grouped_df\n",
    "\n",
    "def pivot_data_to_wide(df, index_cols, pivot_cols, values_cols):\n",
    "    wide_df = df.pivot_table(index=index_cols, columns=pivot_cols, values=values_cols)\n",
    "    wide_df.columns = pd.MultiIndex.from_tuples(wide_df.columns)\n",
    "    wide_df = wide_df.reset_index()\n",
    "    return wide_df\n",
    "\n",
    "def reindex_with_missing_ids(df, all_ids, index_name='NMSKL_ID'):\n",
    "    df = df.set_index('subject').reindex(all_ids).reset_index()\n",
    "    df.index.name = index_name\n",
    "    return df\n",
    "\n",
    "def flatten_multiindex_columns(df):\n",
    "    df.columns = ['_'.join(filter(None, map(str, col))).strip() if isinstance(col, tuple) else col for col in df.columns]\n",
    "    return df\n",
    "\n",
    "def save_excel(df, filepath, sheet_name, mode='w'):\n",
    "    with pd.ExcelWriter(filepath, engine='openpyxl', mode=mode) as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "# Main processing\n",
    "def main():\n",
    "    # Load and calculate additional columns\n",
    "    all_df = pd.read_csv('all_processed_df.csv')  # Assuming input data is loaded from a CSV\n",
    "    all_df = calculate_additional_columns(all_df)\n",
    "\n",
    "    # Save grouped data to CSV files\n",
    "    df_means = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected'], 'means_bysubject.csv')\n",
    "    df_meansdur = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected', 'Duration'], 'means_bysubjectandduration.csv')\n",
    "\n",
    "    # Filter and save Day 1 means\n",
    "    df1_means = df_means[df_means['day'] == 'Day1']\n",
    "    df1_means[['subject', 'group', 'day', 'Condition', 'Affected'] + VARLIST].to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject.csv'), index=False)\n",
    "\n",
    "    # Convert long data to wide format for Day 1 and save\n",
    "    df1_wide = pivot_data_to_wide(df1_means, ['subject', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "    df1_wide = reindex_with_missing_ids(df1_wide, ALL_IDS)\n",
    "    df1_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "    df1_wide.sort_values(['group', 'KINARM_ID'], ascending=True).to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject_wide.csv'), index=False)\n",
    "\n",
    "    # Excel Sheet Creation for Multiple Days\n",
    "    exceltitle = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Auto_Format.xlsx')\n",
    "    exceltitle2 = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Long_Format.xlsx')\n",
    "\n",
    "    for day_num in range(1, MAX_DAYS + 1):\n",
    "        current_day = f'Day{day_num}'\n",
    "\n",
    "        # Process Day-Wise Wide Format Data\n",
    "        df_day_means = df_means[df_means['day'] == current_day]\n",
    "        df_day_wide = pivot_data_to_wide(df_day_means, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "        df_day_wide = reindex_with_missing_ids(df_day_wide, ALL_IDS)\n",
    "        df_day_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "\n",
    "        # Process Day-Wise Data by Duration\n",
    "        df_day_meansdur = df_meansdur[df_meansdur['day'] == current_day]\n",
    "        df_day_widedur = pivot_data_to_wide(df_day_meansdur, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected', 'Duration'], VARLIST)\n",
    "        df_day_widedur = reindex_with_missing_ids(df_day_widedur, ALL_IDS)\n",
    "        df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
    "\n",
    "        # Combine the data and write to Excel\n",
    "        df_day_combo = pd.concat([df_day_wide, df_day_widedur], axis=1)\n",
    "        df_day_combo = df_day_combo.loc[:, ~df_day_combo.columns.duplicated()]  # Remove duplicate columns\n",
    "        df_day_combo = flatten_multiindex_columns(df_day_combo)  # Flatten multi-index columns\n",
    "\n",
    "        if day_num == 1:\n",
    "            save_excel(df_day_combo, exceltitle, f'{current_day}_Master_Formatted', mode='w')\n",
    "        else:\n",
    "            save_excel(df_day_combo, exceltitle, f'{current_day}_Master_Formatted', mode='a')\n",
    "\n",
    "    # Save long format Excel file for all days\n",
    "    df_meansdur = flatten_multiindex_columns(df_meansdur)  # Flatten multi-index columns\n",
    "    save_excel(df_meansdur, exceltitle2, 'AllDays_Master_Formatted', mode='w')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "506b6734-3834-4d8e-9aef-d01d9474dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define constants\n",
    "RESULTS_DIR = r'C:\\Users\\LibraryUser\\Downloads\\Fall2024\\BrainAndAction\\CP\\CP\\resv2'  # Ensure this directory is defined\n",
    "TOTAL_IDS = 88\n",
    "ALL_IDS = ['cpvib' + str(item).zfill(3) for item in range(1, TOTAL_IDS + 1)]\n",
    "MAX_DAYS = 5\n",
    "VARLIST = ['age', 'Accuracy', 'RT', 'MT', 'velPeak', 'pathlength', 'CT', 'xPosError', 'RTalt', 'IA_abs']\n",
    "\n",
    "# Helper functions\n",
    "def calculate_additional_columns(df):\n",
    "    df['IA_abs'] = np.abs(df['IA_50RT'])\n",
    "    df['pathNorm'] = df['pathlength'] / df['straightlength']\n",
    "    df['xTargetabs'] = np.abs(df['xTargetEnd'])\n",
    "    return df\n",
    "\n",
    "def save_grouped_data(df, group_cols, filename):\n",
    "    # Using numeric_only=True to avoid issues with non-numeric columns\n",
    "    grouped_df = df.groupby(group_cols).mean(numeric_only=True).reset_index()\n",
    "    grouped_df.to_csv(os.path.join(RESULTS_DIR, filename), index=False)\n",
    "    return grouped_df\n",
    "\n",
    "def pivot_data_to_wide(df, index_cols, pivot_cols, values_cols):\n",
    "    wide_df = df.pivot_table(index=index_cols, columns=pivot_cols, values=values_cols)\n",
    "    wide_df.columns = wide_df.columns.to_flat_index()\n",
    "    wide_df = wide_df.reset_index()\n",
    "    return wide_df\n",
    "\n",
    "def reindex_with_missing_ids(df, all_ids, index_name='NMSKL_ID'):\n",
    "    df = df.set_index('subject').reindex(all_ids).reset_index()\n",
    "    df.index.name = index_name\n",
    "    return df\n",
    "\n",
    "def save_excel(df, filepath, sheet_name, mode='w'):\n",
    "    with pd.ExcelWriter(filepath, engine='openpyxl', mode=mode) as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "def process_and_save_day_data(df_means, df_meansdur, day_num, exceltitle, all_ids):\n",
    "    current_day = f'Day{day_num}'\n",
    "\n",
    "    # Process Day-Wise Wide Format Data\n",
    "    df_day_means = df_means[df_means['day'] == current_day]\n",
    "    df_day_wide = pivot_data_to_wide(df_day_means, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "    df_day_wide = reindex_with_missing_ids(df_day_wide, all_ids)\n",
    "    df_day_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "\n",
    "    # Process Day-Wise Data by Duration\n",
    "    df_day_meansdur = df_meansdur[df_meansdur['day'] == current_day]\n",
    "    df_day_widedur = pivot_data_to_wide(df_day_meansdur, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected', 'Duration'], VARLIST)\n",
    "    df_day_widedur = reindex_with_missing_ids(df_day_widedur, all_ids)\n",
    "    df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
    "\n",
    "    # Combine the data and write to Excel\n",
    "    df_day_combo = pd.concat([df_day_wide, df_day_widedur], axis=1, join=\"inner\")\n",
    "    if day_num == 1:\n",
    "        save_excel(df_day_combo, exceltitle, f'{current_day}_Master_Formatted', mode='w')\n",
    "    else:\n",
    "        save_excel(df_day_combo, exceltitle, f'{current_day}_Master_Formatted', mode='a')\n",
    "\n",
    "# Main processing\n",
    "def main():\n",
    "    # Load and calculate additional columns\n",
    "    all_df = pd.read_csv('all_processed_df.csv')  # Assuming input data is loaded from a CSV\n",
    "    all_df = calculate_additional_columns(all_df)\n",
    "\n",
    "    # Save grouped data to CSV files\n",
    "    df_means = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected'], 'means_bysubject.csv')\n",
    "    df_meansdur = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected', 'Duration'], 'means_bysubjectandduration.csv')\n",
    "\n",
    "    # Filter and save Day 1 means\n",
    "    df1_means = df_means[df_means['day'] == 'Day1']\n",
    "    df1_means[['subject', 'group', 'day', 'Condition', 'Affected'] + VARLIST].to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject.csv'), index=False)\n",
    "\n",
    "    # Convert long data to wide format for Day 1 and save\n",
    "    df1_wide = pivot_data_to_wide(df1_means, ['subject', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "    df1_wide = reindex_with_missing_ids(df1_wide, ALL_IDS)\n",
    "    df1_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "    df1_wide.sort_values(['group', 'KINARM_ID'], ascending=True).to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject_wide.csv'), index=False)\n",
    "\n",
    "    # Excel Sheet Creation for Multiple Days\n",
    "    exceltitle = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Auto_Format.xlsx')\n",
    "    exceltitle2 = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Long_Format.xlsx')\n",
    "\n",
    "    for day_num in range(1, MAX_DAYS + 1):\n",
    "        process_and_save_day_data(df_means, df_meansdur, day_num, exceltitle, ALL_IDS)\n",
    "\n",
    "    # Save long format Excel file for all days\n",
    "    save_excel(df_meansdur, exceltitle2, 'AllDays_Master_Formatted', mode='w')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "67976e55-0f9b-49d0-bbfd-3e398e8d7ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define constants\n",
    "RESULTS_DIR = r'C:\\Users\\LibraryUser\\Downloads\\Fall2024\\BrainAndAction\\CP\\CP\\resv2'  # Ensure this directory is defined\n",
    "TOTAL_IDS = 88\n",
    "ALL_IDS = ['cpvib' + str(item).zfill(3) for item in range(1, TOTAL_IDS + 1)]\n",
    "MAX_DAYS = 5\n",
    "VARLIST = ['Accuracy','MT','RT','pathlength','velPeak']\n",
    "# Helper functions\n",
    "def calculate_additional_columns(df):\n",
    "    df['pathNorm'] = df['pathlength'] / df['straightlength']\n",
    "    df['xTargetabs'] = np.abs(df['xTargetEnd'])\n",
    "    return df\n",
    "\n",
    "def save_grouped_data(df, group_cols, filename):\n",
    "    # Using numeric_only=True to avoid issues with non-numeric columns\n",
    "    grouped_df = df.groupby(group_cols).mean(numeric_only=True).reset_index()\n",
    "    grouped_df.to_csv(os.path.join(RESULTS_DIR, filename), index=False)\n",
    "    return grouped_df\n",
    "\n",
    "def pivot_data_to_wide(df, index_cols, pivot_cols, values_cols):\n",
    "    wide_df = df.pivot_table(index=index_cols, columns=pivot_cols, values=values_cols)\n",
    "    wide_df.columns = wide_df.columns.to_flat_index()\n",
    "    wide_df = wide_df.reset_index()\n",
    "    return wide_df\n",
    "\n",
    "def reindex_with_missing_ids(df, all_ids, index_name='NMSKL_ID'):\n",
    "    df = df.set_index('subject').reindex(all_ids).reset_index()\n",
    "    df.index.name = index_name\n",
    "    return df\n",
    "\n",
    "def save_excel(df, filepath, sheet_name, mode='w'):\n",
    "    with pd.ExcelWriter(filepath, engine='openpyxl', mode=mode) as writer:\n",
    "        df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "def process_and_save_day_data(df_means, df_meansdur, day_num, exceltitle, all_ids):\n",
    "    current_day = f'Day{day_num}'\n",
    "    varlist = ['Accuracy','MT','RT','pathlength','velPeak']\n",
    "    # Process Day-Wise Wide Format Data\n",
    "    df_day_means = df_means[df_means['day'] == current_day]\n",
    "    df_day_wide = pivot_data_to_wide(df_day_means, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "    df_day_wide = reindex_with_missing_ids(df_day_wide, all_ids)\n",
    "    df_day_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "\n",
    "    # Process Day-Wise Data by Duration\n",
    "    df_day_meansdur = df_meansdur[df_meansdur['day'] == current_day]\n",
    "    df_day_widedur = pivot_data_to_wide(df_day_meansdur, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected', 'Duration'], VARLIST)\n",
    "    df_day_widedur = reindex_with_missing_ids(df_day_widedur, all_ids)\n",
    "    df_day_widedur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
    "\n",
    "    # Combine the data and write to Excel\n",
    "    df_day_combo = pd.concat([df_day_wide, df_day_widedur], axis=1, join=\"inner\")\n",
    "    if day_num == 1:\n",
    "        save_excel(df_day_combo, exceltitle, f'{current_day}_Master_Formatted', mode='w')\n",
    "    else:\n",
    "        save_excel(df_day_combo, exceltitle, f'{current_day}_Master_Formatted', mode='a')\n",
    "\n",
    "# Main processing\n",
    "def main():\n",
    "    # Load and calculate additional columns\n",
    "    all_df = pd.read_csv('all_processed_df.csv')  # Assuming input data is loaded from a CSV\n",
    "    all_df = calculate_additional_columns(all_df)\n",
    "\n",
    "    # Save grouped data to CSV files\n",
    "    df_means = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected'], 'means_bysubject.csv')\n",
    "    df_meansdur = save_grouped_data(all_df, ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected', 'Duration'], 'means_bysubjectandduration.csv')\n",
    "\n",
    "    # Filter and save Day 1 means\n",
    "    df1_means = df_means[df_means['day'] == 'Day1']\n",
    "    df1_means[['subject', 'group', 'day', 'Condition', 'Affected'] + VARLIST].to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject.csv'), index=False)\n",
    "\n",
    "    # Convert long data to wide format for Day 1 and save\n",
    "    df1_wide = pivot_data_to_wide(df1_means, ['subject', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "    df1_wide = reindex_with_missing_ids(df1_wide, ALL_IDS)\n",
    "    df1_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "    df1_wide.sort_values(['group', 'KINARM_ID'], ascending=True).to_csv(os.path.join(RESULTS_DIR, 'Day1_means_bysubject_wide.csv'), index=False)\n",
    "\n",
    "    # Excel Sheet Creation for Multiple Days\n",
    "    exceltitle = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Auto_Format.xlsx')\n",
    "    exceltitle2 = os.path.join(RESULTS_DIR, 'UL_KINARM_Mastersheet_Long_Format.xlsx')\n",
    "    varlist = ['Accuracy','MT','RT','pathlength','velPeak']\n",
    "    for day_num in range(1, MAX_DAYS + 1):\n",
    "        process_and_save_day_data(df_means, df_meansdur, day_num, exceltitle, ALL_IDS)\n",
    "\n",
    "    # Save long format Excel file for all days\n",
    "    save_excel(df_meansdur, exceltitle2, 'AllDays_Master_Formatted', mode='w')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ee53070-6411-4519-ace4-173d3ddcb4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('all_processed_df.csv')\n",
    "varlist = ['age', 'Accuracy', 'RT', 'MT', 'velPeak', 'pathlength', 'CT', 'xPosError',\n",
    "                   # 'targetDist','targetlength'\n",
    "                   'RTalt', 'IA_abs', 'EndPointError', 'IDE', 'PLR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f4d0e9b7-f190-46d3-81d7-cc5264fa644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = clean_data(all_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e9663b80-3653-4945-bbcd-c9a3d4bb8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means, df_meansdur, df_stds, df_stdsdur, df1_means, df1_stds, df2_means, df2_stds = save_data_to_csv(\n",
    "            all_df, varlist)\n",
    "prepare_excel_export(df_means, df_meansdur,df_stds,df_stdsdur ,RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f810814d-d0d8-45e5-a567-3665e7ee6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RESULTS_DIR = r'C:\\Users\\LibraryUser\\Downloads\\Fall2024\\BrainAndAction\\CP\\CP\\resv2'\n",
    "\n",
    "def save_data_to_csv(all_df, varlist):\n",
    "    results_dir = RESULTS_DIR\n",
    "    group_cols = ['group', 'visit', 'studyid', 'subject', 'day', 'Condition', 'Affected']\n",
    "\n",
    "    # Select numeric columns\n",
    "    numeric_cols = all_df.select_dtypes(include=[np.number]).columns\n",
    "    all_df_numeric = all_df[group_cols + list(numeric_cols)].copy()\n",
    "\n",
    "    # Group by the relevant columns and calculate the mean\n",
    "    df_means = all_df_numeric.groupby(group_cols).mean().reset_index()\n",
    "    df_means.to_csv(os.path.join(results_dir, 'means_bysubject.csv'))\n",
    "\n",
    "    # Group by the relevant columns including 'Duration' and calculate the mean\n",
    "    df_meansdur = all_df_numeric.groupby(group_cols + ['Duration']).mean().reset_index()\n",
    "    df_meansdur.to_csv(os.path.join(results_dir, 'means_bysubjectandduration.csv'))\n",
    "\n",
    "    # Filter for Accuracy == 1\n",
    "    hit_df = all_df_numeric.loc[all_df['Accuracy'] == 1]\n",
    "\n",
    "    # Separate by Day 1 and Day 2 and save as CSV\n",
    "    df1_means = df_means.loc[df_means['day'] == 'Day1']\n",
    "    df1_means[['subject', 'group', 'day', 'Condition', 'Affected'] + varlist].to_csv('Day1_means_bysubject.csv')\n",
    "\n",
    "    df2_means = df_means.loc[df_means['day'] == 'Day2']\n",
    "    df2_means[['subject', 'group', 'day', 'Condition', 'Affected'] + varlist].to_csv('Day2_means_bysubject.csv')\n",
    "\n",
    "    # Long to wide format conversion\n",
    "    df1_wide = df1_means.pivot_table(index=[\"subject\", \"studyid\", \"group\", \"day\"],\n",
    "                                     columns=['Condition', 'Affected'], values=varlist)\n",
    "    df2_wide = df2_means.pivot_table(index=[\"subject\", \"studyid\", \"group\", \"day\"],\n",
    "                                     columns=['Condition', 'Affected'], values=varlist)\n",
    "\n",
    "    # Sort and save wide format\n",
    "    df1_wide.sort_values(['group', 'subject'], ascending=True).to_csv(\n",
    "        os.path.join(results_dir, 'Day1_means_bysubject_wide.csv'))\n",
    "    df2_wide.sort_values(['group', 'subject'], ascending=True).to_csv(\n",
    "        os.path.join(results_dir, 'Day2_means_bysubject_wide.csv'))\n",
    "\n",
    "    return df_means, df1_means, df2_means\n",
    "\n",
    "\n",
    "def prepare_excel_export(df_means, df_meansdur, results_dir, totalids=88, max_days=5):\n",
    "    # Generate all possible subject IDs\n",
    "    allids = ['cpvib' + str(item).zfill(3) for item in range(1, totalids + 1)]\n",
    "    varlist = ['Accuracy', 'MT', 'RT', 'pathlength', 'velPeak', 'EndPointError', 'IDE', 'PLR', 'PLR_2']\n",
    "    exceltitle = os.path.join(results_dir, 'UL KINARM Mastersheet Auto Format.xlsx')\n",
    "    exceltitle2 = os.path.join(results_dir, 'UL KINARM Mastersheet Long Format.xlsx')\n",
    "\n",
    "    # Create a mapping from variable names to their order\n",
    "    variable_order = {var: idx for idx, var in enumerate(varlist)}\n",
    "\n",
    "    for thisday in range(1, max_days + 1):\n",
    "        day_label = 'Day' + str(thisday)\n",
    "        df1_means = df_means.loc[df_means['day'] == day_label]\n",
    "\n",
    "        # Pivot to wide format for df_means\n",
    "        df1_wide = df1_means.pivot_table(\n",
    "            index=[\"subject\", \"visit\", \"studyid\", \"group\", \"day\"],\n",
    "            columns=['Condition', 'Affected'],\n",
    "            values=varlist\n",
    "        )\n",
    "\n",
    "        # Flatten MultiIndex columns\n",
    "        df1_wide.columns = df1_wide.columns.to_flat_index()\n",
    "\n",
    "        # Sort columns based on the desired variable order\n",
    "        df1_wide = df1_wide[sorted(df1_wide.columns, key=lambda x: (\n",
    "            variable_order.get(x[0], len(varlist)), x[1], x[2]))]\n",
    "\n",
    "        # Reset index to turn MultiIndex into columns\n",
    "        df1_wide = df1_wide.reset_index(level=[\"subject\", \"visit\", \"group\", \"day\"])\n",
    "\n",
    "        # Ensure all subject IDs are present\n",
    "        missing = list(set(allids) - set(df1_wide['subject'].astype(str)))\n",
    "        if missing:\n",
    "            # Create a DataFrame for missing IDs with NaN values\n",
    "            missing_df = pd.DataFrame({'subject': missing})\n",
    "            df1_wide = pd.concat([df1_wide, missing_df], ignore_index=True, sort=False)\n",
    "\n",
    "        df1_wide.index.name = 'NMSKL_ID'\n",
    "        df1_wide = df1_wide.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'})\n",
    "\n",
    "        # Process and save to Excel\n",
    "        sheet_name = f'Day{thisday}_Master_Formatted'\n",
    "        if thisday == 1:\n",
    "            with pd.ExcelWriter(exceltitle) as writer:\n",
    "                df1_wide.to_excel(writer, sheet_name=sheet_name)\n",
    "        else:\n",
    "            with pd.ExcelWriter(exceltitle, engine=\"openpyxl\", mode='a') as writer:\n",
    "                df1_wide.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "    # Write the long format DataFrame to a separate Excel file\n",
    "    with pd.ExcelWriter(exceltitle2) as writer:\n",
    "        df_meansdur.to_excel(writer, sheet_name='AllDays_Master_Formatted')\n",
    "\n",
    "\n",
    "all_df = pd.read_csv('all_processed_df.csv')\n",
    "varlist = ['Accuracy','MT','RT','pathlength','velPeak']\n",
    "# Call the function\n",
    "df_means, df1_means, df2_means = save_data_to_csv(all_df, varlist)\n",
    "prepare_excel_export(df_means, df_meansdur, results_dir, totalids=88, max_days=5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbaa9d2-4bf0-4ae0-987b-a72ded415079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "36faa8bb-76d5-4682-adb9-e662bb687a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_day_data_std(df_std, df_stddur, day_num, exceltitle, all_ids):\n",
    "    current_day = f'Day{day_num}'\n",
    "    \n",
    "    # Process Day-Wise Wide Format Data for Standard Deviation (means by subject)\n",
    "    df_day_std = df_std[df_std['day'] == current_day]\n",
    "    df_day_wide_std = pivot_data_to_wide(df_day_std, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected'], VARLIST)\n",
    "\n",
    "    # Ensure all expected columns are present in the pivot result for means by subject\n",
    "    all_expected_columns = ['subject', 'visit', 'studyid', 'group', 'day'] + [\n",
    "        (var, condition, affected)\n",
    "        for var in VARLIST\n",
    "        for condition in ['Interception', 'Reaching']\n",
    "        for affected in ['Less Affected', 'More Affected']\n",
    "    ]\n",
    "    \n",
    "    # Reindex to ensure that all expected columns are present, filling missing columns with NaN\n",
    "    df_day_wide_std = df_day_wide_std.reindex(columns=all_expected_columns, fill_value=np.nan)\n",
    "    df_day_wide_std = reindex_with_missing_ids(df_day_wide_std, all_ids)\n",
    "    df_day_wide_std.rename(columns={'subject': 'KINARM_ID', 'day': 'Visit_day'}, inplace=True)\n",
    "\n",
    "    # Process Day-Wise Data for Standard Deviation by Duration\n",
    "    df_day_stddur = df_stddur[df_stddur['day'] == current_day]\n",
    "    df_day_wide_stddur = pivot_data_to_wide(df_day_stddur, ['subject', 'visit', 'studyid', 'group', 'day'], ['Condition', 'Affected', 'Duration'], VARLIST)\n",
    "\n",
    "    # Ensure all expected columns for durations are present in the pivot result\n",
    "    all_expected_columns_dur = ['subject', 'visit', 'studyid', 'group', 'day'] + [\n",
    "        (var, condition, affected, duration)\n",
    "        for var in VARLIST\n",
    "        for condition in ['Interception', 'Reaching']\n",
    "        for affected in ['Less Affected', 'More Affected']\n",
    "        for duration in [500, 625, 750, 900]  # Replace with the actual durations you expect\n",
    "    ]\n",
    "    \n",
    "    # Reindex to ensure that all expected columns for duration are present, filling missing columns with NaN\n",
    "    df_day_wide_stddur = df_day_wide_stddur.reindex(columns=all_expected_columns_dur, fill_value=np.nan)\n",
    "    df_day_wide_stddur = reindex_with_missing_ids(df_day_wide_stddur, all_ids)\n",
    "    df_day_wide_stddur.drop(columns=['subject', 'visit', 'day', 'group'], inplace=True)\n",
    "\n",
    "    # Combine the wide format data for means by subject and duration\n",
    "    df_day_combo_std = pd.concat([df_day_wide_std, df_day_wide_stddur], axis=1, join=\"inner\")\n",
    "\n",
    "    # Write the combined data to Excel\n",
    "    if day_num == 1:\n",
    "        save_excel(df_day_combo_std, exceltitle, f'{current_day}_Master_Formatted_STD', mode='w')\n",
    "    else:\n",
    "        save_excel(df_day_combo_std, exceltitle, f'{current_day}_Master_Formatted_STD', mode='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b9ef8-384d-449a-a087-0f271a15dd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
