'''
@author: Santosh Kumar
@desc: This script is used to calculate the PVar for the given data.
@date: 2021/09/29
'''
import json
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats
import math
import CHEATCP_Final_With_IE as cf
from scipy.interpolate import interp1d
from scipy.interpolate import splrep, splev
from Config import define_defaults, BASE_DIR, mdf, MASTER_FILE, MATFILES_DIR, DEFAULTS, RESULTS_DIR, consider_window_for_intial_plan
import traceback

PVAR_RESULTS_DIR = os.path.join(RESULTS_DIR, 'PVAR_RESULTS')


def generate_data():
    PVAR_RESULTS_DIR = os.path.join(RESULTS_DIR, 'PVAR_RESULTS')
    all_df, allTrajs = cf.getDataCP(mdf, MATFILES_DIR, DEFAULTS)
    all_df.to_csv(os.path.join(PVAR_RESULTS_DIR,'all_df_for_pvar.csv'), index=False)
    return all_df, allTrajs
'''
We will be just loading the data from all_df which is generated by executing the getDataCP function from CHEATCP_Final_With_IE.py
'''
def load_data():
    try:
        all_df, allTrajs = generate_data()   #TODO: Not needed to generate data again. Just load the data from the file.
        reaching_trials_df = all_df[all_df['Condition'] == 'Reaching']
        return reaching_trials_df
    except Exception as e:
        print(f"An error occurred while loading data with getDataCP: {e}")
        traceback.print_exc()
        exit(1)

def preprocess_data(all_df):

    trials_list = []
    for i, row in all_df.iterrows():
        if not pd.isna(row['HandX_filt']) and not pd.isna(row['HandY_filt']):
            HandX = np.array(eval(row['HandX_filt']))
            HandY = np.array(eval(row['HandY_filt']))
            RT = int(row['RT']) if not pd.isna(row['RT']) else 0
            CT = int(row['CT']) if not pd.isna(row['CT']) else len(HandX)
            if len(HandX) > 1 and len(HandY) > 1 and RT >= 0 and CT <= len(HandX) and RT < CT:
                trials_list.append({
                    'HandX': eval(HandX),  # Convert string back to list if necessary
                    'HandY': eval(HandY),
                    'RT': RT,
                    'CT': CT,
                    'Subject': row['subject'],
                    'Day': row['day'],
                    'Condition': row['Condition'],
                    'Arm': row['Affected'],
                    'Duration': row['Duration']
                })
    print(f"Prepared {len(trials_list)} valid trials for PVar computation.")
    return trials_list

def time_normalize_trial(trial, num_points=500):
    """
    Takes a single trial dict with keys:
      - 'HandX': numpy array of x positions
      - 'HandY': numpy array of y positions
      - 'RT': reaction time index (int)
      - 'CT': completion time index (int)
    and returns two arrays: (normX, normY) each of length `num_points`.
    If something is invalid, returns (None, None).
    """
    HandX = trial.get('HandX', np.array([]))
    HandY = trial.get('HandY', np.array([]))
    RT = trial.get('RT', 0)
    CT = trial.get('CT', len(HandX))

    # Basic checks
    if (RT < 0 or CT > len(HandX) or RT >= CT):
        return None, None  # invalid indices

    # Slice the movement portion
    segX = HandX[RT:CT]
    segY = HandY[RT:CT]

    if len(segX) < 2:
        return None, None  # not enough data to interpolate

    # Create a time vector for the original segment (0..1)
    original_t = np.linspace(0, 1, len(segX))
    new_t = np.linspace(0, 1, num_points)

    # Use a spline or linear interpolation
    try:
        # Option A: Spline interpolation (splrep + splev)
        tck_x = splrep(original_t, segX, s=0)
        tck_y = splrep(original_t, segY, s=0)
        normX = splev(new_t, tck_x)
        normY = splev(new_t, tck_y)

        # Option B (comment out above, uncomment below for linear):
        # normX = np.interp(new_t, original_t, segX)
        # normY = np.interp(new_t, original_t, segY)

        return np.array(normX), np.array(normY)

    except Exception as e:
        # If interpolation fails for some reason
        print(f"Interpolation error for trial: {e}")
        return None, None


def make_trial_dict(row):
    """
    Convert a single DataFrame row to a dictionary with the keys we need
    for time normalization and eventually PVar.
    """
    # Convert string to array if needed:
    HandX = np.array(row['HandX_filt']) if isinstance(row['HandX_filt'], list) else np.array([])
    HandY = np.array((row['HandY_filt'])) if isinstance(row['HandY_filt'],list) else np.array([])
    RT = int(row['RT']) if not pd.isna(row['RT']) else 0
    CT = int(row['CT']) if not pd.isna(row['CT']) else len(HandX)

    # Build the dictionary
    return {
        'HandX': HandX,
        'HandY': HandY,
        'RT': RT,
        'CT': CT,
        'Subject': row['subject'],
        'Day': row['day'],
        'Condition': row['Condition'],
        'Arm': row['Affected'],
        'Duration': row['Duration']
    }


def group_trials(all_df):
    """
    Group trials by [Subject, Day, Condition, Arm, Duration].
    Returns a dictionary where each key is (Subject, Day, Condition, Arm, Duration),
    and the value is a list of trial dicts for that group.
    """
    # List of columns that define a unique condition
    group_cols = ['subject', 'day', 'Affected', 'Duration']
    group_dict = {}
    for idx, row in all_df.iterrows():
        # Build the trial dict
        trial = make_trial_dict(row)

        # Basic validity check (e.g., if HandX is empty, skip):
        if len(trial['HandX']) < 2:
            continue
        
        # Create the group key (tuple) from the row
        group_key = (
            trial['Subject'],
            trial['Day'],
            trial['Arm'],
            trial['Duration']
        )

        # Insert into the dictionary
        if group_key not in group_dict:
            group_dict[group_key] = []
        group_dict[group_key].append(trial)

    print(f"Created {len(group_dict)} groups of trials.")
    return group_dict

def plot_group_trajectories(trial_list, mean_x, mean_y, group_key, num_points=500, save_dir="PVAR_Plots"):
    """
    For each trial in trial_list, time-normalize,
    plot in a faint color, then plot the mean in red.
    """
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    plt.figure(figsize=(8, 6))
    n_plotted = 0
    for trial in trial_list:
        normX, normY = time_normalize_trial(trial, num_points=num_points)
        if normX is not None and normY is not None:
            plt.plot(normX, normY, color='blue', alpha=0.2)
            n_plotted += 1

    # Plot the mean in red
    if mean_x is not None and mean_y is not None:
        plt.plot(mean_x, mean_y, color='red', linewidth=2, label='Mean')

    plt.title(f"Group: {group_key}\n Plotted {n_plotted} trials")
    plt.xlabel("X")
    plt.ylabel("Y")
    plt.legend()
    plt.grid(True)

    # Save figure
    filename = "_".join([str(x) for x in group_key]) + ".png"
    plt.savefig(os.path.join(save_dir, filename))
    plt.close()


def compute_pvar_for_group(trial_list, num_points=500):
    """
    Given a list of trial dicts (all from the same group), time-normalize
    each trial and compute path variability (Pvar).

    Returns a tuple: (Pvar, mean_traj_x, mean_traj_y, n_valid)
     - Pvar: float or None (if fewer than 2 valid trials)
     - mean_traj_x: array of shape (num_points,) or None
     - mean_traj_y: same shape as mean_traj_x
     - n_valid: how many trials were successfully time-normalized
    """
    all_norm_x = []
    all_norm_y = []

    for trial in trial_list:
        normX, normY = time_normalize_trial(trial, num_points=num_points)
        # Only keep if not None
        if normX is not None and normY is not None:
            all_norm_x.append(normX)
            all_norm_y.append(normY)

    if len(all_norm_x) < 2:
        # Not enough data to compute a standard deviation across trials
        return None, None, None, len(all_norm_x)

    # Convert to arrays: shape (nTrials, num_points)
    norm_x = np.array(all_norm_x)
    norm_y = np.array(all_norm_y)

    # Compute mean trajectory
    mean_traj_x = np.mean(norm_x, axis=0)
    mean_traj_y = np.mean(norm_y, axis=0)

    # Deviations
    dev_x = norm_x - mean_traj_x
    dev_y = norm_y - mean_traj_y

    # Standard deviations at each time point
    std_x = np.std(dev_x, axis=0)
    std_y = np.std(dev_y, axis=0)

    # Sum them up to get Pvar
    # You can also do radial: sum of sqrt(std_x^2 + std_y^2) if you prefer
    Pvar = np.sum(std_x + std_y)

    return Pvar, mean_traj_x, mean_traj_y, len(all_norm_x)


def main():
    # 1) Load only Reaching DataFrame
    reaching_df = load_data()
    
    # 2) Group them by (Subject, Day, Arm, Duration)
    group_dict = group_trials(reaching_df)
    print(f"We have {len(group_dict)} total groups from the DataFrame.")

    pvar_results = []  # we will store Pvar for each group

    # 3) For each group key (subj, day, arm, duration), compute pvar
    for key, trial_list in group_dict.items():
        subj, day, arm, duration = key

        Pvar, mean_traj_x, mean_traj_y, n_valid = compute_pvar_for_group(trial_list, num_points=500)
        
        if Pvar is None:
            print(f"Group {key} has fewer than 2 valid normalized trials (n={n_valid}), skipping.")
            continue

        # Store results
        pvar_results.append({
            'Subject': subj,
            'Day': day,
            'Arm': arm,
            'Duration': duration,
            'Pvar': Pvar,
            'nValidTrials': n_valid
        })

        print(f"Group {key}: Pvar={Pvar:.2f} using {n_valid} trials.")

        # (Optional) If you want to do a quick plot of the mean trajectory:
        # plot_group_trajectories(trial_list, mean_traj_x, mean_traj_y, ...)

    # 4) Convert to DataFrame and save
    pvar_df = pd.DataFrame(pvar_results)
    print("\n--- Pvar Results ---")
    print(pvar_df)
    plot_group_trajectories(trial_list, mean_traj_x, mean_traj_y, key, num_points=500)

    # If you want to pivot table or save to Excel:
    pvar_df.to_csv(os.path.join(PVAR_RESULTS_DIR, "pvar_results.csv"), index=False)





if __name__ == "__main__":  
    main()